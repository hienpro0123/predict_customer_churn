{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a5e700-0185-4631-a70c-49206aa730ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170d2a55-cb2b-4aa2-8e59-74e0c07dd010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Read file by using AWS\n",
    "df_train = spark.read.csv(\n",
    "    \"s3a://churn-databricks/raw/customer_churn_dataset-training-master.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df_test = spark.read.csv(\n",
    "    \"s3a://churn-databricks/raw/customer_churn_dataset-testing-master.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b689556-233d-407d-8552-ed3c9637cf21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_train = spark.read.csv(\n",
    "    \"/Volumes/workspace/default/data_customers/customer_churn_dataset-training-master.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")\n",
    "\n",
    "df_test = spark.read.csv(\n",
    "    \"/Volumes/workspace/default/data_customers/customer_churn_dataset-testing-master.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb054257-a783-4b84-a20a-5e4869b559ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a6945b-0d91-4e5a-92ac-0288cc513254",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(\"CustomerID\")\n",
    "df_test = df_test.drop(\"CustomerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ead52f-615d-482b-ac55-94087e4e3d61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e54ddc7-e5a9-4501-b896-524ae21e2ebb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "363366c6-499a-4dd9-9aba-9b18ab5221f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ce72ff-65ca-4b99-bf18-0ae9e78d9a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, sum, when\n",
    "\n",
    "missing_df_train= df_train.select([\n",
    "    sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in df_train.columns\n",
    "])\n",
    "\n",
    "display(missing_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f701f193-c403-4a19-8681-bb9429ee55bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "\n",
    "df_train.select([\n",
    "    sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in df_train.columns\n",
    "]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5cbf0f-4a93-4a87-aedb-499fa957b36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.dropDuplicates()\n",
    "df_test = df_test.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1119cb39-f9ef-4d27-a7b1-bcf69379d839",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "for c in df_train.columns:\n",
    "    print(c, df_train.select(c).distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65fc17e0-af20-45b2-aab3-95c5828eddc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "churn_pd = df_train.select(\"Churn\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.countplot(x='Churn', data=churn_pd)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f'{int(p.get_height())}',\n",
    "        (p.get_x() + p.get_width()/2., p.get_height()),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bbf8b73-65ca-43b9-b90a-81d6149a4169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    f.name for f in df_train.schema.fields\n",
    "    if f.dataType.simpleString() in [\"int\", \"double\"]\n",
    "    and f.name != \"Churn\"\n",
    "]\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8376543-b16e-4a09-bcf5-078dc9c6a68b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for col in num_cols:\n",
    "    \n",
    "    # convert c·ªôt Spark -> Pandas\n",
    "    data = df_train.select(col).toPandas()[col]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Histogram\n",
    "    axes[0].hist(data, bins=30, density=True, alpha=0.7)\n",
    "    axes[0].set_title(f\"Histogram of {col}\")\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel(\"Density\")\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    # KDE\n",
    "    sns.kdeplot(data, fill=True, ax=axes[1], color='orange')\n",
    "    axes[1].set_title(f\"KDE of {col}\")\n",
    "    axes[1].set_xlabel(col)\n",
    "    axes[1].set_ylabel(\"Density\")\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c634120-c50b-44b5-a083-b5248b2a294e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# N·∫øu data l·ªõn th√¨ sample tr∆∞·ªõc\n",
    "sample_df = df_train.sample(fraction=0.2, seed=42)\n",
    "\n",
    "for col in num_cols:\n",
    "    \n",
    "    # Spark -> Pandas\n",
    "    data = sample_df.select(col).toPandas()[col]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "    # Boxplot\n",
    "    axes[0].boxplot(\n",
    "        data,\n",
    "        vert=False,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='skyblue', alpha=0.7),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[0].set_title(f\"Boxplot of {col}\")\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # Violin Plot\n",
    "    sns.violinplot(\n",
    "        x=data,\n",
    "        ax=axes[1],\n",
    "        inner='quartile',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[1].set_title(f\"Violin Plot of {col}\")\n",
    "    axes[1].set_xlabel(col)\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71657f98-5e28-45aa-a47b-6ec158ade51b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "churn_rate = (\n",
    "    df_train\n",
    "    .groupBy(\"Support Calls\")\n",
    "    .agg(avg(\"Churn\").alias(\"churn_rate\"))\n",
    "    .orderBy(\"Support Calls\")\n",
    ")\n",
    "\n",
    "churn_pd = churn_rate.toPandas()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(churn_pd['Support Calls'], churn_pd['churn_rate'])\n",
    "\n",
    "plt.xlabel(\"Number of Support Calls\")\n",
    "plt.ylabel(\"Churn Rate\")\n",
    "plt.title(\"Churn Rate by Support Calls\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eccb7db3-08c7-4873-b9a0-977272eb4779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols = num_cols + [\"Churn\"]\n",
    "pdf = df_train.select(cols).toPandas()\n",
    "\n",
    "corr = pdf.corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix including Churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82e50c67-ce98-465f-8dac-a8e3b66db581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6601e729-def4-42fc-9c25-5b613fb0ae08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols = [f.name for f in df_train.schema.fields \n",
    "                    if f.dataType.simpleString() == 'string']\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93ae9b6-d123-47d4-a9b5-e307b90aab83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    print(f\"\\n===== {col} =====\")\n",
    "    df_train.groupBy(col).count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470ac12c-9244-4372-a17a-2bb7a0cb4235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to√†n b·ªô categorical columns sang pandas m·ªôt l·∫ßn\n",
    "pdf = df_train.select(categorical_cols).toPandas()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    sns.countplot(\n",
    "        x=pdf[col],\n",
    "        order=pdf[col].value_counts().index\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"{col} Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78bb9632-3316-4fad-ad69-e23f72243772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Engineering : New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71635b37-cbb1-414f-b2b9-568925437636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Train\n",
    "df_train = df_train.withColumn(\n",
    "    \"Age_group\",\n",
    "    when(col(\"Age\") < 30, \"Young (<30)\")\n",
    "    .when((col(\"Age\") >= 30) & (col(\"Age\") < 50), \"Adult (30-50)\")\n",
    "    .otherwise(\"Senior (50+)\")\n",
    ")\n",
    "\n",
    "# Test\n",
    "df_test = df_test.withColumn(\n",
    "    \"Age_group\",\n",
    "    when(col(\"Age\") < 30, \"Young (<30)\")\n",
    "    .when((col(\"Age\") >= 30) & (col(\"Age\") < 50), \"Adult (30-50)\")\n",
    "    .otherwise(\"Senior (50+)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb3dac97-e6ff-4b47-a315-836bc09a988c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spark -> Pandas\n",
    "pdf = df_train.select(\"Age_group\", \"Churn\").toPandas()\n",
    "\n",
    "# Group & pivot b·∫±ng pandas\n",
    "pivot = (\n",
    "    pdf.groupby([\"Age_group\", \"Churn\"])\n",
    "       .size()\n",
    "       .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "pivot.plot(kind='bar')\n",
    "plt.title('Age Group vs Churn')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Churn')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cdd0fcb-4c15-484c-b9dc-219bcbfb18d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check Last Interaction with Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f528ed4-d6af-41f8-a1b2-14832a89b7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spark -> Pandas\n",
    "pdf = df_train.select(\"Last Interaction\", \"Churn\").toPandas()\n",
    "\n",
    "# Group + pivot\n",
    "pivot = (\n",
    "    pdf.groupby([\"Last Interaction\", \"Churn\"])\n",
    "       .size()\n",
    "       .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Chu·∫©n ho√° theo % t·ª´ng h√†ng\n",
    "pivot_norm = pivot.div(pivot.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "pivot_norm.plot(kind='bar', stacked=True)\n",
    "\n",
    "plt.title(\"Percentage Distribution of Churn by Last Interaction\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xlabel(\"Last Interaction\")\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e60e21d9-facd-47b0-9f63-1c1aa44dc40e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4.Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dffc6445-aa7e-4738-b61e-d394caeffb2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# ===== TRAIN =====\n",
    "df_train = df_train \\\n",
    "    .withColumn(\"Usage_Per_Tenure\",\n",
    "                col(\"Usage Frequency\") / (col(\"Tenure\") + 1)) \\\n",
    "    .withColumn(\"Spend_Per_Usage\",\n",
    "                col(\"Total Spend\") / (col(\"Usage Frequency\") + 1)) \\\n",
    "    .withColumn(\"Spend_Per_Tenure\",\n",
    "                col(\"Total Spend\") / (col(\"Tenure\") + 1)) \\\n",
    "    .withColumn(\"Payment_Delay_Ratio\",\n",
    "                col(\"Payment Delay\") / 30) \\\n",
    "    .withColumn(\"Engagement_Score\",\n",
    "                (col(\"Usage Frequency\") * col(\"Total Spend\")) / 1000)\n",
    "\n",
    "# ===== TEST =====\n",
    "df_test = df_test \\\n",
    "    .withColumn(\"Usage_Per_Tenure\",\n",
    "                col(\"Usage Frequency\") / (col(\"Tenure\") + 1)) \\\n",
    "    .withColumn(\"Spend_Per_Usage\",\n",
    "                col(\"Total Spend\") / (col(\"Usage Frequency\") + 1)) \\\n",
    "    .withColumn(\"Spend_Per_Tenure\",\n",
    "                col(\"Total Spend\") / (col(\"Tenure\") + 1)) \\\n",
    "    .withColumn(\"Payment_Delay_Ratio\",\n",
    "                col(\"Payment Delay\") / 30) \\\n",
    "    .withColumn(\"Engagement_Score\",\n",
    "                (col(\"Usage Frequency\") * col(\"Total Spend\")) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03310af5-a716-43d6-9f60-1b49204cb7e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=c,\n",
    "        outputCol=c+\"_index\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for c in categorical_cols\n",
    "]\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[c+\"_index\" for c in categorical_cols],\n",
    "    outputCols=[c+\"_vec\" for c in categorical_cols]\n",
    ")\n",
    "\n",
    "numeric_cols = [f.name for f in df_train.schema.fields \n",
    "                if f.dataType.simpleString() in ['int', 'double']\n",
    "                and f.name != \"Churn\"]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=numeric_cols + [c+\"_vec\" for c in categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [encoder, assembler])\n",
    "\n",
    "df_train_processed = pipeline.fit(df_train).transform(df_train)\n",
    "\n",
    "# Fit tr√™n TRAIN\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "\n",
    "# Transform TRAIN\n",
    "df_train_processed = pipeline_model.transform(df_train)\n",
    "\n",
    "# Transform TEST (quan tr·ªçng!)\n",
    "df_test_processed = pipeline_model.transform(df_test)\n",
    "\n",
    "display(df_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f28c972-9d75-46d9-999f-b0de5aa366d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2a918e-158b-4cea-a861-0e2b39cdb63d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_full = df_train_processed\n",
    "test_final = df_test_processed\n",
    "\n",
    "train_data, val_data = train_full.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455733c3-a174-42eb-9f66-cdca265313f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier,\n",
    "    LinearSVC\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"Churn\",\n",
    "        maxIter=100\n",
    "    ),\n",
    "\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"Churn\",\n",
    "        maxDepth=5\n",
    "    ),\n",
    "\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"Churn\",\n",
    "        numTrees=100,\n",
    "        maxDepth=5\n",
    "    ),\n",
    "\n",
    "    \"Gradient Boosting\": GBTClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"Churn\",\n",
    "        maxIter=50\n",
    "    ),\n",
    "\n",
    "    \"Linear SVM\": LinearSVC(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"Churn\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf37159b-5e13-482c-aa02-4794891741ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator\n",
    ")\n",
    "\n",
    "auc_eval = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Churn\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Churn\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Churn\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"recallByLabel\"\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    fitted = model.fit(train_data)\n",
    "    preds = fitted.transform(val_data)\n",
    "\n",
    "    results[name] = {\n",
    "        \"AUC\": auc_eval.evaluate(preds),\n",
    "        \"Accuracy\": acc_eval.evaluate(preds),\n",
    "        \"Recall\": recall_eval.evaluate(preds)\n",
    "    }\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values(\"AUC\", ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d432923e-6b11-4d08-a4f3-138cad803fa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "print(\"Best model:\", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c54011-0b68-4487-8ce7-df171a20957c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_full = df_train_processed\n",
    "\n",
    "best_model = models[best_model_name].fit(train_full)\n",
    "\n",
    "final_preds = best_model.transform(df_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd0358a-d454-4301-9171-3639fffc0691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pdf = final_preds.select(\"Churn\", \"prediction\").toPandas()\n",
    "\n",
    "print(classification_report(pdf[\"Churn\"], pdf[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebab1b4d-aa8d-4647-8971-0d0049091c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "import os\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/workspace/default/mlflow_tmp\"\n",
    "\n",
    "with mlflow.start_run(run_name=best_model_name):\n",
    "\n",
    "    mlflow.log_metric(\"Test_AUC\", auc_eval.evaluate(final_preds))\n",
    "    mlflow.log_metric(\"Test_Accuracy\", acc_eval.evaluate(final_preds))\n",
    "    mlflow.log_metric(\"Test_Recall\", recall_eval.evaluate(final_preds))\n",
    "\n",
    "    mlflow.spark.log_model(best_model, \"model\")\n",
    "\n",
    "print(\"Logged to MLflow üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Customer_Churn_SparkML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
